---
---

@article{cherrat2023quantum,
  abbr={Quantum},
  bibtex_show={true},
  title={Quantum Deep Hedging},
  author={Cherrat, El Amine and Raj, Snehal and Kerenidis, Iordanis and Shekhar, Abhishek and Wood, Ben and Dee, Jon and Chakrabarti, Shouvanik and Chen, Richard and Herman, Dylan and Hu, Shaohan and Minssen, Pierre and Shaydulin, Ruslan and Sun, Yue and Yalovetzky, Romina and Pistoia, Marco},
  journal={Quantum},
  volume={7},
  pages={1191},
  year={2023},
  doi={10.22331/q-2023-11-29-1191},
  html={https://quantum-journal.org/papers/q-2023-11-29-1191/},
  abstract={Quantum machine learning techniques are being explored for a variety of financial applications. In this work, we develop a quantum approach for the problem of deep hedging, a machine learning approach for managing the risk associated with derivatives trading.},
  selected={true}
}

@article{coyle2025training,
  abbr={npj QI},
  bibtex_show={true},
  title={Training-Efficient Density Quantum Machine Learning},
  author={Coyle, Brian and Raj, Snehal and Mathur, Natansh and Cherrat, El Amine and Jain, Nishant and Kazdaghli, Sofiene and Kerenidis, Iordanis},
  journal={npj Quantum Information},
  volume={11},
  number={1},
  pages={172},
  year={2025},
  publisher={Nature Publishing Group},
  html={https://www.nature.com/articles/s41534-025-01099-6},
  abstract={We introduce a novel approach to quantum machine learning that leverages density matrices for more efficient training. Our method demonstrates improved sample complexity and training efficiency compared to traditional quantum neural network approaches.},
  selected={true}
}

@article{raj2025quic,
  abbr={arXiv},
  bibtex_show={true},
  title={QuIC: Quantum-Inspired Compound Adapters for Parameter Efficient Fine-Tuning},
  author={Raj, Snehal and Coyle, Brian},
  journal={arXiv preprint arXiv:2502.06916},
  year={2025},
  html={https://arxiv.org/abs/2502.06916},
  abstract={We introduce QuIC, quantum-inspired adapter modules that operate with less than 0.02% memory footprint while maintaining pretrained representations through orthogonal weight parameters. Evaluated on LLaMA and vision transformers, our advanced configurations achieve over 40x compression compared to LoRA.},
  selected={true}
}

@article{mathur2025bayesian,
  abbr={arXiv},
  bibtex_show={true},
  title={Bayesian Quantum Orthogonal Neural Networks for Anomaly Detection},
  author={Mathur, Natansh and Coyle, Brian and Jain, Nishant and Raj, Snehal and Tandon, Akshat and Krauser, Jasper Simon and Stoessel, Rainer},
  journal={arXiv preprint arXiv:2504.18103},
  year={2025},
  html={https://arxiv.org/abs/2504.18103},
  abstract={We propose a Bayesian approach to quantum orthogonal neural networks for anomaly detection tasks. Our method combines the expressiveness of quantum neural networks with Bayesian uncertainty quantification.},
  selected={true}
}

@inproceedings{nangi2021autosumm,
  abbr={EMNLP},
  bibtex_show={true},
  title={AUTOSUMM: Automatic Model Creation for Text Summarization},
  author={Nangi, Sharmila Reddy and Tyagi, Atharv and Mundra, Jay and Mukherjee, Sagnik and Snehal, Raj and Chhaya, Niyati and Garimella, Aparna},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={9981--9991},
  year={2021},
  organization={Association for Computational Linguistics},
  html={https://aclanthology.org/2021.emnlp-main.798/},
  abstract={We present AutoSumm, a system for automatic model creation for text summarization. Our approach enables the automated development of customized summarization models without extensive manual intervention.},
  selected={true}
}

@misc{mahapatra2024autocreation,
  abbr={Patent},
  bibtex_show={true},
  title={Auto-creation of Custom Models for Text Summarization},
  author={Mahapatra, Sumit and Chhaya, Niyati and Raj, Snehal and Nangi, Sharmila Reddy and Nair, Sarthak},
  year={2024},
  note={US Patent 12,045,272},
  html={https://patents.google.com/patent/US12045272B2/en}
}

@mastersthesis{raj2022graphical,
  abbr={Oxford},
  bibtex_show={true},
  title={Graphical Calculus for Tensor Network Contractions},
  author={Raj, Snehal},
  school={University of Oxford},
  year={2022},
  type={Master's thesis},
  html={https://www.cs.ox.ac.uk/people/aleks.kissinger/theses/raj-thesis.pdf},
  abstract={We develop graphical calculus techniques for tensor network contractions, with applications to the simulation of quantum circuits. Our methods improve upon existing classical simulation techniques for quantum supremacy circuits.}
}

@thesis{singh2020block,
  abbr={IIT-K},
  bibtex_show={true},
  title={Block Multilinear Degree},
  author={Singh, Aditya Kumar and Kar, Supriya and Raj, Snehal},
  school={Indian Institute of Technology Kanpur},
  year={2020},
  type={Bachelor's thesis},
  abstract={We study the block multilinear degree of polynomials and its applications to quantum query complexity.}
}
